# Variational_AutoEncoder_MNIST

This project implements a Variational Autoencoder (VAE) for reconstructing images from the MNIST dataset. The VAE learns a compressed representation of the input images and reconstructs them with minimal loss, while also learning a meaningful latent space.  

---

## Dataset and Preprocessing  
- **Dataset:** MNIST, consisting of 70,000 grayscale images of handwritten digits (28x28 pixels).  
- **Preprocessing Steps:**  
  - Normalized pixel values to the range [0,1].  
  - Converted images to PyTorch tensors.  
  - Split into three sets:  
    - Training  
    - Validation  
    - Test  
  - Loaded using `DataLoader` for efficient batching.  

---

## Model Architecture  
The VAE is composed of two main parts:  
1. **Encoder:** Compresses the input image into a latent space representation.  
2. **Decoder:** Reconstructs the image from the latent space.  

### Encoder  
- Consists of two convolutional layers followed by fully connected layers.  
- Extracts meaningful features and encodes them as mean and standard deviation of the latent space.  
- Uses **ReLU** activations and **Batch Normalization** for stable learning.  

### Latent Space  
- Samples from the latent space using a reparameterization trick.  

### Decoder  
- Mirrors the Encoder architecture.  
- Uses transposed convolutional layers to reconstruct the image.  
- Outputs a reconstructed image with pixel values in the range [0,1] using a **Sigmoid** activation.  

---

## Loss Function  
The VAE is trained using a combination of:  
- **Reconstruction Loss:** Measures the difference between the input and reconstructed image using **Binary Cross Entropy (BCE)**.  
- **KL Divergence Loss:** Regularizes the latent space to follow a standard normal distribution.  
- **Total Loss:** Balances reconstruction accuracy and latent space regularization.  

---

## Training and Evaluation  
- **Optimizer:** Adam with a learning rate of 0.001.  
- **Training Process:**  
  - Trained for 20 epochs on the training set.  
  - Validated on the validation set after each epoch.  
  - Saved the best model based on the lowest validation loss.  

### Performance Metrics:  
- **Reconstruction Loss:** Evaluates how well the model reconstructs the input images.  
- **KL Divergence:** Measures how closely the latent space follows a standard normal distribution.  
- **Generated Samples:** Images generated by sampling from the learned latent space.  

---

## How to Run  
1. **Install Dependencies**  
   ```bash
   pip install torch torchvision numpy matplotlib

